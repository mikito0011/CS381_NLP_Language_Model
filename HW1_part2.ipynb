{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Part2 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from decimal import Decimal, getcontext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary. The keys are unique words and values are counts of words.\n",
    "def getWordDictionary(inputFile):\n",
    "    readFile = open(inputFile, \"r\")\n",
    "    wordDict = dict()\n",
    "    \n",
    "    for line in readFile:\n",
    "        words = line.split()\n",
    "        for word in words:\n",
    "            if word in wordDict:\n",
    "                wordDict[word] = wordDict[word]+1\n",
    "            else:\n",
    "                wordDict[word] =1\n",
    "    return wordDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place start and end symbol at each sentence.\n",
    "def cleanFile(inputFile, outputFile):\n",
    "    readFile = open(inputFile, \"r+\")\n",
    "    writeFile = open(outputFile, \"w\")\n",
    "\n",
    "    for line in readFile:\n",
    "        line = line.lower()\n",
    "        line = \" \".join(line.split())\n",
    "        line = \"<s> %s </s> \"%line\n",
    "\n",
    "        writeFile.write(line)\n",
    "    writeFile.close()\n",
    "    return writeFile\n",
    "\n",
    "#Place <unk> for words that appear only once on training file\n",
    "def placeUnk (inputFile,outputFile, wordDict):\n",
    "    readFile = open(inputFile, \"r\")\n",
    "    writeFile = open(outputFile, \"w\")\n",
    "    for line in readFile:\n",
    "        words =line.split()\n",
    "        for word in words:\n",
    "            if wordDict[word]==1:\n",
    "                writeFile.write(\" <unk>\")\n",
    "                del wordDict[word]\n",
    "            else:\n",
    "                writeFile.write(\" \"+word)\n",
    "        writeFile.write('\\n')\n",
    "\n",
    "    writeFile.close()\n",
    "    return writeFile\n",
    "\n",
    "#Place <unk>for words that appear only once on test file and words that do not appear on the training file.\n",
    "def placeUnkForTest(inputFile,outputFile, wordDictTrain):\n",
    "    readFile = open(inputFile, \"r\")\n",
    "    writeFile = open(outputFile, \"w\")\n",
    "    for line in readFile:\n",
    "        words =line.split()\n",
    "        for word in words:\n",
    "            if word not in wordDictTrain:\n",
    "                writeFile.write(\" <unk>\")\n",
    "            else:\n",
    "                writeFile.write(\" \"+word)\n",
    "    writeFile.write('\\n')\n",
    "    writeFile.close()\n",
    "    return writeFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1 Pre-processing text files </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing text files\n"
     ]
    }
   ],
   "source": [
    "print(\"Pre-processing text files\")\n",
    "'''lower case and place start and end symbols, place <unk>,\n",
    "and create word dictionaries of training file '''\n",
    "cleanedTrainFile = cleanFile(\"train.txt\", \"cleanedTrain1.txt\")\n",
    "trainDict = getWordDictionary(cleanedTrainFile.name)\n",
    "cleanedTrainFile_2 = placeUnk(cleanedTrainFile.name, \"cleanedTrain2.txt\",trainDict)\n",
    "trainDict2 = getWordDictionary(cleanedTrainFile_2.name)\n",
    "\n",
    "'''lower case and place start and end symbols, place <unk>,\n",
    "and create word dictionaries of test file '''\n",
    "cleanedTestFile = cleanFile(\"test.txt\", \"cleanedTest1.txt\")\n",
    "testDict = getWordDictionary(cleanedTestFile.name)\n",
    "cleanedTestFile_2 = placeUnkForTest(cleanedTestFile.name, \"cleanedTest2.txt\",trainDict2)\n",
    "testDict2 = getWordDictionary(cleanedTestFile_2.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.3 Questoins </h3>\n",
    "Problem1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 Questions\n",
      "Problem 1\n",
      "Problem1 The number of unique words of the training corpus: 41739\n"
     ]
    }
   ],
   "source": [
    "print(\"1.3 Questions\")\n",
    "print(\"Problem 1\")\n",
    "#vocaburary size for unique words of the training file\n",
    "trainVocabSize = len(trainDict2.keys())\n",
    "print(\"Problem1 The number of unique words of the training corpus:\",trainVocabSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 2\n",
      "The number of tokens in the training corpus: 2568210\n"
     ]
    }
   ],
   "source": [
    "print(\"Problem 2\")\n",
    "#Total number of tokens of training file\n",
    "sumOfTrainTokens = sum(trainDict2.values())\n",
    "print(\"The number of tokens in the training corpus:\", sumOfTrainTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the percentage of missing word typpes on the test file.\n",
    "def getPercentOfMissingTypesUnigram(inputFile, trainDict, testDict):\n",
    "    readFile = open(inputFile, \"r\")\n",
    "    missWordTypeDict = dict()\n",
    "    totalWordType = len(testDict)\n",
    "    \n",
    "    for line in readFile:\n",
    "        words = line.split()\n",
    "        for word in words:\n",
    "            if word not in trainDict:\n",
    "                missWordTypeDict[word] = 1\n",
    "    \n",
    "    return (len(missWordTypeDict)/totalWordType)*100\n",
    "\n",
    "\n",
    "#Return the percentage of missing tokens on the test file.\n",
    "def getPercentOfMissingTokensUnigram(inputFile, trainDict,testDict):\n",
    "    readFile = open(inputFile, \"r\")\n",
    "    countMissing =0\n",
    "    totalTokens = sum(testDict.values())\n",
    "    \n",
    "    for line in readFile:\n",
    "        words = line.split()\n",
    "        for word in words:\n",
    "            if word not in trainDict:\n",
    "                countMissing += 1\n",
    "    return (countMissing/totalTokens)*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 3\n",
      "The percentage of word type missing on the test corpus: 6.00 %\n",
      "The percentage of word tokens missing on the test corpus: 2.75 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Problem 3\")\n",
    "print(\"The percentage of word type missing on the test corpus:\", \n",
    "      \"%.2f\" % getPercentOfMissingTypesUnigram(\"cleanedTest1.txt\", trainDict, testDict), \"%\")\n",
    "print(\"The percentage of word tokens missing on the test corpus:\", \n",
    "      \"%.2f\" % getPercentOfMissingTokensUnigram(\"cleanedTest1.txt\", trainDict, testDict), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return bigram dictionary. The keys are tuple of words, values are counts of the tuple.\n",
    "def getBigramDictionary(inputFile):\n",
    "    readFile = open(inputFile, \"r\")\n",
    "    wordDict = dict()\n",
    "    \n",
    "    for line in readFile:\n",
    "        lineList = line.split()\n",
    "        for i in range(len(lineList) - 1):\n",
    "            biTuple = (lineList[i], lineList[i+1])\n",
    "            if biTuple in wordDict:\n",
    "                wordDict[biTuple] += 1\n",
    "            else:\n",
    "                wordDict[biTuple] = 1\n",
    "    return wordDict\n",
    "\n",
    "#Return the percetage of missing bigram types on the test file.\n",
    "def getPercentOfMissingTypesBigram(inputFile, trainBiDict, testBiDict):\n",
    "    readFile = open(inputFile, \"r\")\n",
    "    missBigramTypeTypeDict =dict()\n",
    "    totalBigramType = sum(testBiDict.values())\n",
    "        \n",
    "    for line in readFile:\n",
    "        lineList = line.split()\n",
    "        for i in range(len(lineList) -1):\n",
    "            biTuple = (lineList[i], lineList[i+1])\n",
    "            if biTuple not in trainBiDict:\n",
    "                missBigramTypeTypeDict[biTuple] = 1\n",
    "                \n",
    "    return (len(missBigramTypeTypeDict)/totalBigramType) *100\n",
    "\n",
    "\n",
    "#Return the percetage of missing bigram tokens on the test file.\n",
    "def getPercentOfMissingTokensBigram(inputFile, trainBiDict):\n",
    "    readFile = open(inputFile, \"r\")\n",
    "    countMissing =0\n",
    "    totalTokens = 0\n",
    "        \n",
    "    for line in readFile:\n",
    "        lineList = line.split()\n",
    "        for i in range(len(lineList) -1):\n",
    "            biTuple = (lineList[i], lineList[i+1])\n",
    "            if biTuple not in trainBiDict:\n",
    "                countMissing += 1\n",
    "                \n",
    "            totalTokens += 1\n",
    "    return (countMissing/totalTokens) *100\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 4\n",
      "The percentage of bigrams types missing on the test corpus: 21.67 %\n",
      "The percentage of bigrams tokens missing on the test corpus: 24.41 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Problem 4\")\n",
    "trainTuple =getBigramDictionary(cleanedTrainFile_2.name)\n",
    "del trainTuple[('</s>', '<s>')]\n",
    "testTuple = getBigramDictionary(cleanedTestFile_2.name)\n",
    "del testTuple[('</s>', '<s>')]\n",
    "\n",
    "print(\"The percentage of bigrams types missing on the test corpus:\", \n",
    "      \"%.2f\" % getPercentOfMissingTypesBigram(cleanedTestFile_2.name, trainTuple, testTuple),'%' )\n",
    "\n",
    "print(\"The percentage of bigrams tokens missing on the test corpus:\", \n",
    "      \"%.2f\" % getPercentOfMissingTokensBigram(cleanedTestFile_2.name, trainTuple),'%' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return unigram probability of a sentence.\n",
    "def unigramProb(sentence, uniDict):\n",
    "    totalTokens = sum(uniDict.values())\n",
    "    prob =1.0\n",
    "    for word in sentence.split():\n",
    "        prob*=(uniDict[word]/totalTokens)\n",
    "    return prob\n",
    "\n",
    "#Return unigram log probability of sentences.\n",
    "def logProbUnigram(sentences, uniDict):\n",
    "    prob = 0.0\n",
    "    sentences = sentences.lower()\n",
    "    #split sentences by\"<end>\". <end> will be assigned after </s> later\n",
    "    for line in sentences.split(\"<end>\"):\n",
    "        sentenceProb = unigramProb(line, uniDict)\n",
    "        \n",
    "        if sentenceProb ==0.0:\n",
    "            return \"undefined\"\n",
    "        else:\n",
    "            prob += math.log(sentenceProb, 2)\n",
    "    return prob\n",
    "\n",
    "#Return bigram probability of a sentence.\n",
    "def bigramProb(sentence, uniDict, biDict):\n",
    "    prob =1.0\n",
    "    lineList = sentence.split()\n",
    "    for i in range(len(lineList) -1):\n",
    "        sentenceTuple = (lineList[i], lineList[i+1])\n",
    "        if sentenceTuple not in biDict:\n",
    "            return 0       \n",
    "        prob *= biDict[sentenceTuple]/(uniDict[lineList[i]])\n",
    "    return prob\n",
    "\n",
    "#Return bigram log probability of sentences.\n",
    "def logProbBigram (sentences, uniDict, biDict):\n",
    "    prob = 0.0\n",
    "    sentences = sentences.lower()\n",
    "    for line in sentences.split(\"<end>\"):\n",
    "        sentenceProb = bigramProb(line, uniDict,biDict)\n",
    "        if sentenceProb==0:\n",
    "            return \"undefined\"\n",
    "        else:\n",
    "            prob += math.log(sentenceProb, 2)\n",
    "    return prob\n",
    "\n",
    "#Return bigram probability of a sentence with smoothing of add-one.\n",
    "def bigramProbAddOne(sentence, uniDict, biDict):\n",
    "    prob =1\n",
    "    lineList = sentence.split()\n",
    "\n",
    "    for i in range(len(lineList) -1):\n",
    "        biTuple = (lineList[i], lineList[i+1])\n",
    "        if biTuple not in biDict:\n",
    "            prob *= (1.0/(uniDict[lineList[i]]+len(uniDict)))\n",
    "        else:\n",
    "            prob *= ((biDict[biTuple]+1) / float(uniDict[lineList[i]]+len(uniDict)))\n",
    "    return prob\n",
    "    \n",
    "#Return bigram log probability of sentences with smoothing of add-one.\n",
    "def logProbBigramAddOne(sentences, uniDict, biDict):\n",
    "    prob = 0.0\n",
    "    sentences = sentences.lower()\n",
    "    for line in sentences.split(\"<end>\"):\n",
    "        sentenceProb = bigramProbAddOne(line, uniDict, biDict)\n",
    "        if sentenceProb==0:\n",
    "            continue\n",
    "        prob += math.log(sentenceProb, 2)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 5\n",
      "The corpus: \" <s> I look forward to hearing your reply . </s> \"\n",
      "Unigram probability with log: -94.93878209357642\n",
      "Bigram probability with log: undefined\n",
      "Bigram probability with log and Add-One: -97.13956016607364\n"
     ]
    }
   ],
   "source": [
    "print(\"Problem 5\")\n",
    "sentence = \"<s> I look forward to hearing your reply . </s>\"\n",
    "print(\"The corpus: \\\"\", sentence, \"\\\"\")\n",
    "print(\"Unigram probability with log:\",logProbUnigram(sentence,trainDict2))\n",
    "print(\"Bigram probability with log:\",\n",
    "      logProbBigram(sentence,trainDict2, trainTuple))\n",
    "print(\"Bigram probability with log and Add-One:\",\n",
    "      logProbBigramAddOne(sentence,trainDict2, trainTuple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPerplexity(langModel, sentences, uniDict, biDict):\n",
    "    \n",
    "    m =0 #number of words in the test data.\n",
    "    l =0 #average probability of senteces\n",
    "\n",
    "    for word in sentences.split():\n",
    "        #if word in <end>, it does not count\n",
    "        if (word !=\"<end>\"):\n",
    "            m +=1\n",
    "    if langModel==\"unigram\":\n",
    "        if logProbUnigram(sentences, uniDict) ==\"undefined\":\n",
    "            return \"Undefined\"\n",
    "        else:\n",
    "            l = (1.0/m) * logProbUnigram(sentences, uniDict)\n",
    "    \n",
    "    if langModel == \"bigram\":\n",
    "        if logProbBigram(sentences, uniDict, biDict) ==\"undefined\":\n",
    "            return \"Undefined\"\n",
    "        else:\n",
    "            l = (1.0/m) * logProbBigram(sentences, uniDict, biDict)\n",
    "    \n",
    "    if langModel == \"bigramAdd-one\":\n",
    "        if logProbBigramAddOne(sentences, uniDict, biDict) == \"undefined\":\n",
    "            return \"Undefined\"\n",
    "        \n",
    "        else:\n",
    "            l = (1.0/m) * logProbBigramAddOne(sentences, uniDict, biDict)\n",
    "            \n",
    "    return math.pow(2, (-1*l)) #return power of 2 to -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 6\n",
      "The corpus: \" <s> I look forward to hearing your reply . </s> \"\n",
      "Perplexity of unigram model: 721.01\n",
      "Perplexity of bigram model: Undefined\n",
      "Perplexity of bigram model with add-one: 839.83\n"
     ]
    }
   ],
   "source": [
    "print(\"Problem 6\")\n",
    "print(\"The corpus: \\\"\", sentence, \"\\\"\")\n",
    "print(\"Perplexity of unigram model:\",\n",
    "      \"%.2f\" % getPerplexity('unigram', sentence, trainDict2, trainTuple ))\n",
    "print(\"Perplexity of bigram model:\", \n",
    "      getPerplexity('bigram', sentence, trainDict2, trainTuple ))\n",
    "print(\"Perplexity of bigram model with add-one:\", \n",
    "      \"%.2f\" % getPerplexity('bigramAdd-one', sentence, trainDict2, trainTuple ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 7\n",
      "Perplexity of unigram model on the test corpus: 1000.2001758263615\n",
      "Perplexity of bigram model on the test corpus: Undefined\n",
      "Perplexity of bigram model with add-one on the test corpus: 1365.080280480167\n"
     ]
    }
   ],
   "source": [
    "testCorpus = \"\"\n",
    "testFile = open(cleanedTestFile_2.name, \"r\")\n",
    "for line in testFile:\n",
    "    line = line.replace(\" </s> \", \" </s> <end> \")\n",
    "    testCorpus += line\n",
    "\n",
    "print(\"Problem 7\")\n",
    "print(\"Perplexity of unigram model on the test corpus:\", \n",
    "      getPerplexity('unigram', testCorpus, trainDict2, trainTuple))\n",
    "print(\"Perplexity of bigram model on the test corpus:\", \n",
    "      getPerplexity('bigram', testCorpus, trainDict2, trainTuple))\n",
    "print(\"Perplexity of bigram model with add-one on the test corpus:\", \n",
    "      getPerplexity('bigramAdd-one', testCorpus, trainDict2, trainTuple))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
